{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw53wz7nE2FU"
      },
      "outputs": [],
      "source": [
        "!pip install segmentation-models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKYpDN5NE4I-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZEIEyPCISkh"
      },
      "outputs": [],
      "source": [
        "TRAIN_DATA_SIZE = 9052\n",
        "VAL_DATA_SIZE = 2246\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P_UmRyXFHgS"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Соотношение размера тестовой выборки к валидационной 80:20\n",
        "'''\n",
        "files_list = os.listdir(\"./data/images\")\n",
        "train_files_list = files_list[:9052]\n",
        "validate_files_list = files_list[9052:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbPsqnynFIBx"
      },
      "outputs": [],
      "source": [
        "def batch_generator(df, sample_size, batch_size):\n",
        "    '''\n",
        "    Генератор батчей\n",
        "        Параметры:\n",
        "        df: Список названий файлов, относящихся к выборке\n",
        "        sample_size: Размер выборки\n",
        "        batch_size: Размер батча\n",
        "    '''\n",
        "    while True:\n",
        "        x_batch = []\n",
        "        y_batch = []\n",
        "        for i in range(batch_size):\n",
        "            img_name = df[randint(0, sample_size-1)]\n",
        "            img = cv2.imread('./data/images/{}'.format(img_name))\n",
        "            mask = cv2.imread('./data/masks/{}'.format(img_name), 0)\n",
        "            mask = mask.reshape(448, 448, 1)\n",
        "            \n",
        "            img = cv2.resize(img, (256, 256))\n",
        "            mask = cv2.resize(mask, (256, 256))\n",
        "            \n",
        "            x_batch += [img]\n",
        "            y_batch += [mask]\n",
        "        x_batch = np.array(x_batch) / 255.\n",
        "        y_batch = np.array(y_batch) / 255.\n",
        "        \n",
        "        yield x_batch, y_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCG6uv3XFO4T"
      },
      "outputs": [],
      "source": [
        "import segmentation_models as sm\n",
        "from segmentation_models import Unet\n",
        "from segmentation_models.losses import bce_jaccard_loss\n",
        "from segmentation_models.metrics import iou_score\n",
        "\n",
        "sm.set_framework('tf.keras')\n",
        "sm.framework()\n",
        "\n",
        "BACKBONE = 'resnet50'\n",
        "\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "model_resnet = Unet(BACKBONE, encoder_weights='imagenet', input_shape=(256, 256, 3))\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model_resnet.compile(adam, loss=bce_jaccard_loss, metrics=[iou_score])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNvPBX5EFcr9"
      },
      "outputs": [],
      "source": [
        "best_w = keras.callbacks.ModelCheckpoint('resnet50_best.h5',\n",
        "                                monitor='val_loss',\n",
        "                                verbose=0,\n",
        "                                save_best_only=True,\n",
        "                                save_weights_only=True,\n",
        "                                mode='auto',\n",
        "                                psave_freq=1)\n",
        "\n",
        "last_w = keras.callbacks.ModelCheckpoint('resnet50_last.h5',\n",
        "                                monitor='val_loss',\n",
        "                                verbose=0,\n",
        "                                save_best_only=False,\n",
        "                                save_weights_only=True,\n",
        "                                mode='auto',\n",
        "                                save_freq=1)\n",
        "\n",
        "\n",
        "callbacks = [best_w, last_w]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7U9TQqKdIKTM"
      },
      "outputs": [],
      "source": [
        "hist = model_resnet.fit_generator(batch_generator(train_files_list, TRAIN_DATA_SIZE, BATCH_SIZE),\n",
        "                    steps_per_epoch=TRAIN_DATA_SIZE // BATCH_SIZE,\n",
        "                    epochs=30,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks,\n",
        "                    validation_data=batch_generator(validate_files_list, VAL_DATA_SIZE, BATCH_SIZE),\n",
        "                    validation_steps=VAL_DATA_SIZE // BATCH_SIZE,\n",
        "                    class_weight=None,\n",
        "                    max_queue_size=10,\n",
        "                    workers=1,\n",
        "                    use_multiprocessing=False,\n",
        "                    shuffle=True,\n",
        "                    initial_epoch=0)\n",
        "\n",
        "model_resnet.save(\"unet_resnet_final.model\", save_format='h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GKkzGkWKD6f"
      },
      "outputs": [],
      "source": [
        "N = np.arange(0, 30)\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(N, hist.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, hist.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.savefig(\"unet_resnet_losses.png\")\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(N, hist.history[\"iou_score\"], label=\"train_iou_score\")\n",
        "plt.plot(N, hist.history[\"val_iou_score\"], label=\"val_iou_score\")\n",
        "plt.title(\"Training and validation iou score\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"iou_score\")\n",
        "plt.legend()\n",
        "plt.savefig(\"unet_resnet_iou_score.png\")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "train_U_Net.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
